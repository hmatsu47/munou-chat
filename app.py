import os
import boto3
import streamlit as st
from dotenv import load_dotenv
from langchain.embeddings import BedrockEmbeddings
from langchain.docstore.document import Document
from langchain.vectorstores.pgvector import PGVector

load_dotenv()

MAX_LENGTH = 300

CONNECTION_STRING = PGVector.connection_string_from_db_params(
    driver=os.environ.get("PGVECTOR_DRIVER", "psycopg2"),
    host=os.environ.get("PGVECTOR_HOST", "localhost"),
    port=int(os.environ.get("PGVECTOR_PORT", "5432")),
    database=os.environ.get("PGVECTOR_DATABASE", "postgres"),
    user=os.environ.get("PGVECTOR_USER", "postgres"),
    password=os.environ.get("PGVECTOR_PASSWORD", ""),
)
COLLECTION_NAME = "munou_goroku"

st.title("äººå·¥ç„¡èƒ½ãŸã„ãŸã‚“ğŸ§ ğŸ¥ğŸŒ€")

# ä¼šè©±å±¥æ­´ãŒãªã„å ´åˆã¯åˆæœŸåŒ–
if "messages" not in st.session_state:
    st.session_state.messages = []
    st.session_state.messages.append({"role": "assistant", "content": "ã‚ˆã‚ã—ãã­ï¼"})

# ä¼šè©±å±¥æ­´ã‚’è¡¨ç¤º
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# å…¥åŠ›æ¬„ã‚’è¡¨ç¤º
prompt = st.chat_input("ãŠã¯ãªã—ã—ã¾ã—ã‚‡ï¼")

if prompt:
    trimed_prompt = prompt.strip()
    # å…¥åŠ›ã‚’è¡¨ç¤º
    with st.chat_message("user"):
        st.markdown(trimed_prompt)
    # å…¥åŠ›ã‚’ä¼šè©±å±¥æ­´ã®æœ«å°¾ã«è¿½åŠ 
    st.session_state.messages.append({"role": "user", "content": trimed_prompt})
    response = "ã”ã‚ã‚“ãªã•ã„ã€é•·ã™ãã¦ã‚ˆãã‚ã‹ã‚Šã¾ã›ã‚“ï¼ã‚‚ã†ã¡ã‚‡ã£ã¨çŸ­ã„è¨€è‘‰ã§è©±ã—ã¦ã­ï¼"
    # æ–‡å­—æ•°ãƒã‚§ãƒƒã‚¯
    if len(trimed_prompt) < MAX_LENGTH:
        # ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢ã‹ã‚‰å¿œç­”ã‚’å–å¾—
        bedrock_client = boto3.client('bedrock-runtime', region_name="ap-northeast-1")
        embeddings = BedrockEmbeddings(
            client=bedrock_client,
            model_id="amazon.titan-embed-text-v1"
        )
        store = PGVector(
            collection_name=COLLECTION_NAME,
            connection_string=CONNECTION_STRING,
            embedding_function=embeddings,
        )
        docs = store.similarity_search_with_score(trimed_prompt)
        count = len(docs)
        add_flag = True
        if count == 0:
            # ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢ã«æ–‡ç« ãŒãªã‘ã‚Œã°ãŠã†ã‚€è¿”ã—ã™ã‚‹
            response = trimed_prompt
        else:
            # è¿‘ã„æ–‡ç« ã‚’è¿”ã™
            response = docs[0][0].page_content
            if trimed_prompt == response:
                # ã™ã§ã«ç™»éŒ²æ¸ˆã¿ã®æ–‡ç« ã¨åŒã˜ãªã‚‰ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢ã«ç™»éŒ²ã—ãªã„
                add_flag = False
        if add_flag:
            # ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢ã«å…¥åŠ›ã‚’è¿½åŠ 
            store.add_documents([Document(page_content=trimed_prompt)])
    # äººå·¥ç„¡èƒ½ã®å¿œç­”ã‚’è¡¨ç¤º
    with st.chat_message("assistant"):
        st.markdown(response)
    # å¿œç­”ã‚’ä¼šè©±å±¥æ­´ã®æœ«å°¾ã«è¿½åŠ 
    st.session_state.messages.append({"role": "assistant", "content": response})